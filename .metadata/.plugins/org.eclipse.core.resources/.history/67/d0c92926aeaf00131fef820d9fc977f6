import main
import supervisedModel
from nltk.corpus import stopwords
import math
from random import *

window_size = 20

def predict_sense_ids_with_data (training_data, test_data_file):
    sense_ids_list = [] #OUTPUT: [ ('word', 'predictedSense', 'actualSense', 'prevContext', 'nextContext', 'senseScores'),...]
    numCorrect = 0
    global window_size
    global target_token
    numIncorrect = 0
    probability_map = supervisedModel.create_probability_map(training_data)  # { word, { senseID, ( P(s), { f, P(f|s) } ) } }
    print "Training complete."
    test_data_list = main.format_data_to_list(test_data_file)
    for i in range(len(test_data_list)):  # for each instance/item in the list of entries
        instance = test_data_list[i]
        # get the list of possible senses for the word from the training data
        #added to check if the word is seen by dictionary before
        if instance[main.word_tag] in probability_map:
            sense_prob_map = get_senses(probability_map, instance, window_size, 0.6)
        # get the max value from the prob_sense_value
            #predicted_sense = max(sense_prob_map, key=sense_prob_map.get)
            #predicted_sense = extension_2_window(probability_map,instance,sense_prob_map)
            predicted_sense = extension_2_random(sense_prob_map)
        else:
            predicted_sense = 0
        
        correct = False
        if (predicted_sense == instance[main.senseID]):
            numCorrect += 1
            correct = True
        else:
            numIncorrect += 1
        # write to a file the word and its sense probability map
           # enter the predicted sense into the sense_ids_map
        sense_ids_list.append((instance[main.word_tag], predicted_sense, instance[main.senseID], instance[main.prev], instance[main.next], sense_prob_map))
    print("Number correct: " + str(numCorrect) + ". Number incorrect: " + str(numIncorrect));
    return sense_ids_list


#Get predicted senseIDs:
def predict_sense_ids(training_data_file, test_data_file):
    return predict_sense_ids_with_data(main.format_data(training_data_file), test_data_file)

def get_senses(probability_map, instance, window_size, penalty_score):
    sense_prob_map = {} # { s, P(s) } Probability map for each possible sense the instance can be
    map_of_senses = probability_map[instance[main.word_tag]]
    for sense in map_of_senses.keys():
        sense_prob_map[sense] = (map_of_senses[sense])[0];  # set initial probability to P(s)
        # map of feature words and probabilities for the sense
        feature_map = (map_of_senses[sense])[1]
        sentence = instance[main.prev] + " " + main.target_token + " " + instance[main.next]
        list_of_features = main.tokenize(sentence)  # feature words for the wordInstance
        list_of_features = supervisedModel.words_in_window(list_of_features, window_size)
        # remove all the stop words
        for item in list_of_features:
            if item in stopwords.words('english'):
                list_of_features.remove(item)
        # stem all the feature words
        for j in range(len(list_of_features)):
            list_of_features[j] = main.stem(list_of_features[j])
        # remove duplicates in the sentence
        list_of_features = list(set(list_of_features))
        # get all the p(f_j|s) from word instance and add it to the sense_prob_map
        for f in list_of_features:
            # if feature word exists in map, update the probability
            if f in feature_map.keys():
                sense_prob_map[sense] *= feature_map[f]
            else:
                sense_prob_map[sense] *= penalty_score
    return sense_prob_map
    

#Returns key with the second highest value:
def get_second_highest(dictionary):
    temp = dictionary.copy()
    highest_value = max(temp, key=temp.get)
    del temp[highest_value]
    second_highest = max(temp, key=temp.get)
    return second_highest

#returns the highest score after changing the window size
def extension_2_window(probability_map, instance, sense_prob_map):   
    highest = max(sense_prob_map, key=sense_prob_map.get)
    if (len(sense_prob_map)==1):
        return highest
    else:
        second_highest = get_second_highest(sense_prob_map)
        #if second highest score is close to the highest, change the window size to 10.
        if (sense_prob_map[highest]-sense_prob_map[second_highest] < math.pow(10,18)):
            new_sense_prob_map = get_senses(probability_map, instance, 10, 0.8)          
            return max(new_sense_prob_map, key=new_sense_prob_map.get)
        else:
            return highest

#returns either the second highest or the highest probability sense given a certain difference        
def extension_2_random(sense_prob_map):
    highest = max(sense_prob_map, key=sense_prob_map.get)
    if (len(sense_prob_map)==1):
        return highest
    else:
        second_highest = get_second_highest(sense_prob_map)
        #if second highest score is close to the highest, change the window size to 10.
        if (sense_prob_map[highest]-sense_prob_map[second_highest] < math.pow(10,18)):
            r = random()
            if(r>.6):       
                return second_highest
            else:
                return highest
        else:
            return highest

def output_to_file (sense_ids_list):
    output = open("predictedSenses.txt", "w")  # output of results
    output.write("Id,Prediction\n")
    word_senses_file = open("probabilities.txt", "w")
    counter = 1
    for item in sense_ids_list:
        word_name = item[0]
        predicted_sense = item[1]
        actual_sense = item[2]
        sense_prob_map = item[5]
        word_senses_file.write(word_name + " - correct sense: " + str(actual_sense) + " - predicted sense: " + str(predicted_sense) + "\n")
        word_senses_file.write(str((actual_sense == predicted_sense)) + "\n")
        for s in sense_prob_map.keys():
            word_senses_file.write("\t" + str(s) + " : " + str(sense_prob_map[s]) + "\n")
        word_senses_file.write("\n")
    
        output.write(str(counter)+","+predicted_sense + "\n")
        counter+=1
    output.close()
    word_senses_file.close()


senses = predict_sense_ids("training_data.data","validation_data.data")
output_to_file (senses)


 
    
